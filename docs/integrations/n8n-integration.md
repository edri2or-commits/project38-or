# n8n Integration Guide - Complete Automation Setup

## Table of Contents

1. [Overview](#overview)
2. [Deployment Options](#deployment-options)
3. [Railway Deployment](#railway-deployment)
4. [n8n REST API](#n8n-rest-api)
5. [Claude Integration Patterns](#claude-integration-patterns)
6. [Workflow Management](#workflow-management)
7. [Python Implementation](#python-implementation)
8. [Production Setup](#production-setup)
9. [Complete Python Client](#complete-python-client)

---

## Overview

n8n is an open-source **workflow automation tool** that connects services, processes data, and triggers actions. For autonomous Claude control, n8n serves as the **orchestration layer** for complex multi-service workflows.

**Key Features:**
- ‚úÖ 400+ pre-built integrations (HTTP, databases, APIs, etc.)
- ‚úÖ Visual workflow builder + JSON export/import
- ‚úÖ REST API for programmatic control
- ‚úÖ Claude AI node for direct integration
- ‚úÖ Self-hosted (full control over data)
- ‚úÖ Version control via JSON export
- ‚úÖ Webhook triggers for real-time automation

**Use Cases for Claude Agent:**
- üîÑ Multi-step deployment pipelines (GitHub ‚Üí Railway ‚Üí Telegram notification)
- üìä Data synchronization (PostgreSQL ‚Üí GCP ‚Üí n8n ‚Üí Telegram)
- üîî Monitoring and alerting (Railway webhook ‚Üí n8n ‚Üí Claude analysis ‚Üí action)
- ü§ñ Complex automation requiring multiple API calls

---

## Deployment Options

### Option 1: Railway Template (Recommended)

**Pros:**
- ‚úÖ One-click deployment
- ‚úÖ Automatic PostgreSQL database
- ‚úÖ Redis for queue management
- ‚úÖ ~$5/month on Hobby plan
- ‚úÖ Public URL included
- ‚úÖ Automatic SSL/HTTPS

**Cons:**
- ‚ùå Limited to Railway infrastructure
- ‚ùå Cold starts on free tier

**Best for:** Production deployment with Railway

### Option 2: Docker Self-Hosted

**Pros:**
- ‚úÖ Full control over infrastructure
- ‚úÖ Can run locally for development
- ‚úÖ Custom configuration

**Cons:**
- ‚ùå Manual setup and maintenance
- ‚ùå Need to manage SSL certificates
- ‚ùå Requires separate database

**Best for:** Local development, testing

### Option 3: n8n Cloud

**Pros:**
- ‚úÖ Fully managed (no infrastructure)
- ‚úÖ Automatic updates
- ‚úÖ Built-in monitoring

**Cons:**
- ‚ùå $20+/month cost
- ‚ùå Less control over data
- ‚ùå Can't customize infrastructure

**Best for:** Quick prototyping, non-sensitive workflows

---

## Railway Deployment

### Step-by-Step Setup

#### 1. Deploy n8n Template

1. **Go to Railway n8n template:**
   - Visit: https://railway.com/deploy/n8n
   - Or search "n8n" in Railway templates

2. **Click "Deploy Now"**
   - Select your Railway account
   - Choose project name (e.g., "n8n-automation")

3. **Configure Environment Variables:**

   Railway auto-configures most variables, but verify these:

   ```bash
   # Required
   N8N_ENCRYPTION_KEY=<auto-generated-32-char-string>
   N8N_USER_MANAGEMENT_JWT_SECRET=<auto-generated-32-char-string>

   # PostgreSQL (auto-configured from Railway Postgres service)
   DB_TYPE=postgresdb
   DB_POSTGRESDB_HOST=${{Postgres.PGHOST}}
   DB_POSTGRESDB_PORT=${{Postgres.PGPORT}}
   DB_POSTGRESDB_DATABASE=${{Postgres.PGDATABASE}}
   DB_POSTGRESDB_USER=${{Postgres.PGUSER}}
   DB_POSTGRESDB_PASSWORD=${{Postgres.PGPASSWORD}}

   # n8n Configuration
   N8N_HOST=n8n-production.up.railway.app  # Your Railway domain
   N8N_PORT=5678
   N8N_PROTOCOL=https
   WEBHOOK_URL=https://n8n-production.up.railway.app/
   ```

4. **Wait for Deployment:**
   - Railway builds Docker image (~2-3 minutes)
   - PostgreSQL service starts
   - n8n service starts and connects to database

5. **Get Public URL:**
   - Railway generates URL: `https://<project-name>-production.up.railway.app`
   - Click on service ‚Üí Settings ‚Üí Generate Domain

#### 2. Initial n8n Setup

1. **Visit n8n URL** (first-time setup wizard)

2. **Create Owner Account:**
   ```
   Email: your-email@example.com
   Password: <secure-password-from-GCP-Secret-Manager>
   ```

   **Security:** Store credentials in GCP Secret Manager:
   ```bash
   echo -n "your-secure-password" | gcloud secrets create N8N-OWNER-PASSWORD \
     --data-file=- \
     --project=project38-483612
   ```

3. **Skip Setup Wizard** (we'll configure via API)

#### 3. Generate API Key

1. **Navigate to Settings:**
   - Click user icon (top right) ‚Üí Settings

2. **Go to "n8n API":**
   - Settings ‚Üí n8n API

3. **Create API Key:**
   - Label: "Claude Agent"
   - Expiration: Never (or 365 days for production)
   - Click "Create API Key"

4. **Copy API Key** (shown only once!)

5. **Store in GCP Secret Manager:**
   ```bash
   echo -n "n8n_api_abc123..." | gcloud secrets create N8N-API \
     --data-file=- \
     --project=project38-483612
   ```

#### 4. Verify Installation

```python
import httpx
import asyncio
from src.secrets_manager import SecretManager

async def verify_n8n():
    """Verify n8n API access."""

    manager = SecretManager()
    api_key = manager.get_secret("N8N-API")

    headers = {"X-N8N-API-KEY": api_key}
    base_url = "https://n8n-production.up.railway.app/api/v1"

    async with httpx.AsyncClient() as client:
        # Test API access
        response = await client.get(f"{base_url}/workflows", headers=headers)
        print(f"‚úì API access: {response.status_code}")

        # List workflows
        workflows = response.json()
        print(f"‚úì Workflows: {len(workflows['data'])} found")

asyncio.run(verify_n8n())
```

---

## n8n REST API

### Base Configuration

```
API Endpoint: https://<your-n8n-domain>/api/v1
Authentication: X-N8N-API-KEY header
```

### API Endpoints

#### Workflows

| Endpoint | Method | Purpose |
|----------|--------|---------|
| `/workflows` | GET | List all workflows |
| `/workflows/{id}` | GET | Get workflow details |
| `/workflows` | POST | Create new workflow |
| `/workflows/{id}` | PUT | Update workflow |
| `/workflows/{id}` | DELETE | Delete workflow |
| `/workflows/{id}/activate` | POST | Activate workflow |
| `/workflows/{id}/deactivate` | POST | Deactivate workflow |

#### Executions

| Endpoint | Method | Purpose |
|----------|--------|---------|
| `/executions` | GET | List executions |
| `/executions/{id}` | GET | Get execution details |
| `/executions/{id}` | DELETE | Delete execution |
| `/workflows/{id}/execute` | POST | Execute workflow manually |

#### Credentials

| Endpoint | Method | Purpose |
|----------|--------|---------|
| `/credentials` | GET | List credentials |
| `/credentials/{id}` | GET | Get credential details |
| `/credentials` | POST | Create credential |
| `/credentials/{id}` | PUT | Update credential |
| `/credentials/{id}` | DELETE | Delete credential |

### Common Operations

#### List Workflows

```python
import httpx

async def list_workflows(api_key: str, base_url: str):
    """List all n8n workflows."""

    headers = {"X-N8N-API-KEY": api_key}

    async with httpx.AsyncClient() as client:
        response = await client.get(f"{base_url}/workflows", headers=headers)
        response.raise_for_status()

        data = response.json()
        return data["data"]  # List of workflow objects
```

**Response:**

```json
{
  "data": [
    {
      "id": "1",
      "name": "Deploy to Railway",
      "active": true,
      "createdAt": "2026-01-12T10:00:00.000Z",
      "updatedAt": "2026-01-12T15:00:00.000Z",
      "tags": ["deployment", "railway"]
    }
  ]
}
```

#### Execute Workflow

```python
async def execute_workflow(
    workflow_id: str,
    api_key: str,
    base_url: str,
    input_data: dict = None
):
    """
    Execute n8n workflow manually.

    Args:
        workflow_id: n8n workflow ID
        api_key: n8n API key
        base_url: n8n API base URL
        input_data: Optional input data for workflow

    Returns:
        Execution result dict
    """

    headers = {"X-N8N-API-KEY": api_key}

    url = f"{base_url}/workflows/{workflow_id}/execute"

    async with httpx.AsyncClient(timeout=60.0) as client:
        response = await client.post(
            url,
            headers=headers,
            json=input_data or {}
        )

        response.raise_for_status()
        return response.json()
```

**Response:**

```json
{
  "data": {
    "executionId": "exec-123",
    "finished": true,
    "mode": "manual",
    "startedAt": "2026-01-12T15:00:00.000Z",
    "stoppedAt": "2026-01-12T15:00:05.000Z",
    "data": {
      "resultData": {
        "runData": {
          "Start": [...],
          "HTTP Request": [...],
          "Set": [...]
        }
      }
    }
  }
}
```

#### Get Execution Status

```python
async def get_execution_status(
    execution_id: str,
    api_key: str,
    base_url: str
):
    """Get execution status and results."""

    headers = {"X-N8N-API-KEY": api_key}

    url = f"{base_url}/executions/{execution_id}"

    async with httpx.AsyncClient() as client:
        response = await client.get(url, headers=headers)
        response.raise_for_status()

        data = response.json()
        return {
            "id": data["id"],
            "finished": data["finished"],
            "mode": data["mode"],
            "startedAt": data["startedAt"],
            "stoppedAt": data["stoppedAt"],
            "status": "success" if data["finished"] else "running"
        }
```

#### Create Workflow from JSON

```python
async def create_workflow(
    workflow_json: dict,
    api_key: str,
    base_url: str
):
    """
    Create new workflow from JSON definition.

    Args:
        workflow_json: n8n workflow JSON structure
        api_key: n8n API key
        base_url: n8n API base URL

    Returns:
        Created workflow dict
    """

    headers = {"X-N8N-API-KEY": api_key}

    async with httpx.AsyncClient() as client:
        response = await client.post(
            f"{base_url}/workflows",
            headers=headers,
            json=workflow_json
        )

        response.raise_for_status()
        return response.json()
```

---

## Claude Integration Patterns

### Pattern A: n8n Calls Claude (HTTP Request ‚Üí Claude API)

**Use Case:** n8n workflow needs AI analysis/generation

**Flow:**
```
n8n Trigger ‚Üí HTTP Request (Claude API) ‚Üí Process Response ‚Üí Action
```

**Example Workflow:**

```json
{
  "name": "Analyze Deployment Logs with Claude",
  "nodes": [
    {
      "name": "Webhook",
      "type": "n8n-nodes-base.webhook",
      "position": [250, 300],
      "webhookId": "deploy-logs"
    },
    {
      "name": "HTTP Request - Claude API",
      "type": "n8n-nodes-base.httpRequest",
      "position": [450, 300],
      "parameters": {
        "url": "https://api.anthropic.com/v1/messages",
        "method": "POST",
        "authentication": "genericCredentialType",
        "genericAuthType": "httpHeaderAuth",
        "headerParameters": {
          "parameters": [
            {
              "name": "x-api-key",
              "value": "={{$credentials.anthropicApi.apiKey}}"
            },
            {
              "name": "anthropic-version",
              "value": "2023-06-01"
            }
          ]
        },
        "body": {
          "model": "claude-sonnet-4-5-20250929",
          "max_tokens": 1024,
          "messages": [
            {
              "role": "user",
              "content": "Analyze these deployment logs and identify any errors: {{$json.logs}}"
            }
          ]
        }
      }
    },
    {
      "name": "Send Telegram Alert",
      "type": "n8n-nodes-base.telegram",
      "position": [650, 300],
      "parameters": {
        "text": "Deployment Analysis:\n\n{{$json.content[0].text}}"
      }
    }
  ],
  "connections": {
    "Webhook": {
      "main": [[{"node": "HTTP Request - Claude API"}]]
    },
    "HTTP Request - Claude API": {
      "main": [[{"node": "Send Telegram Alert"}]]
    }
  }
}
```

**Pros:**
- ‚úÖ Simple setup (no custom code)
- ‚úÖ Works with any n8n trigger
- ‚úÖ Claude analyzes data in workflow

**Cons:**
- ‚ùå Limited to single API call
- ‚ùå Can't handle complex multi-turn interactions

### Pattern B: Claude Orchestrates n8n (Claude ‚Üí n8n API)

**Use Case:** Claude needs to trigger complex multi-step workflows

**Flow:**
```
Claude Decision ‚Üí n8n API (execute workflow) ‚Üí n8n runs ‚Üí Result to Claude
```

**Example:**

```python
from src.n8n_client import N8nClient

async def deploy_with_notifications():
    """Claude triggers n8n workflow that deploys and sends notifications."""

    client = N8nClient(
        api_key=manager.get_secret("N8N-API"),
        base_url="https://n8n-production.up.railway.app/api/v1"
    )

    # Claude decides to deploy
    result = await client.execute_workflow(
        workflow_id="deploy-railway-with-notifications",
        input_data={
            "service": "web",
            "environment": "production",
            "notify": True
        }
    )

    # Wait for completion
    execution_id = result["data"]["executionId"]
    status = await client.wait_for_execution(execution_id)

    return status
```

**Pros:**
- ‚úÖ Claude has full control
- ‚úÖ Can chain multiple workflows
- ‚úÖ Complex decision logic in Claude

**Cons:**
- ‚ùå Requires n8n workflows to be pre-built
- ‚ùå Claude can't see intermediate steps

### Pattern C: Bidirectional (Webhooks + API)

**Use Case:** Real-time collaboration between Claude and n8n

**Flow:**
```
Event ‚Üí n8n webhook ‚Üí Claude analysis ‚Üí n8n API ‚Üí Execute action ‚Üí Result webhook ‚Üí Claude
```

**Example Use Case:**

1. **Railway deployment fails** ‚Üí sends webhook to n8n
2. **n8n triggers Claude** (HTTP Request) to analyze logs
3. **Claude analyzes** and decides on fix
4. **Claude triggers n8n workflow** (via API) to apply fix
5. **n8n workflow** creates PR, triggers tests, deploys
6. **n8n sends result** webhook back to Claude
7. **Claude updates** issue with outcome

**Implementation:**

```python
# Claude webhook handler (FastAPI)
@app.post("/n8n-webhook")
async def handle_n8n_webhook(request: Request):
    """Receive webhook from n8n workflow."""

    data = await request.json()

    if data["type"] == "deployment-failed":
        # Analyze failure
        analysis = await analyze_deployment_failure(data["logs"])

        # Trigger fix workflow
        n8n_client = N8nClient(...)
        await n8n_client.execute_workflow(
            workflow_id="apply-deployment-fix",
            input_data={"fix": analysis["recommended_fix"]}
        )

    return {"status": "processed"}
```

**Pros:**
- ‚úÖ Real-time bidirectional communication
- ‚úÖ Complex multi-stage workflows
- ‚úÖ Full autonomy

**Cons:**
- ‚ùå Most complex setup
- ‚ùå Requires webhook endpoint (Railway app)

---

## Workflow Management

### Export Workflows (Version Control)

#### Manual Export (UI)

1. Open workflow in n8n
2. Click "..." menu (top right)
3. Select "Download"
4. Save JSON file

#### Programmatic Export

```python
async def export_all_workflows(api_key: str, base_url: str, output_dir: str):
    """
    Export all n8n workflows to JSON files for version control.

    Args:
        api_key: n8n API key
        base_url: n8n API base URL
        output_dir: Directory to save workflow JSON files
    """
    import json
    from pathlib import Path

    headers = {"X-N8N-API-KEY": api_key}

    async with httpx.AsyncClient() as client:
        # List all workflows
        response = await client.get(f"{base_url}/workflows", headers=headers)
        workflows = response.json()["data"]

        output_path = Path(output_dir)
        output_path.mkdir(exist_ok=True)

        for workflow in workflows:
            # Get full workflow details
            response = await client.get(
                f"{base_url}/workflows/{workflow['id']}",
                headers=headers
            )

            workflow_data = response.json()

            # Save to file
            filename = f"{workflow['name'].replace(' ', '-').lower()}.json"
            filepath = output_path / filename

            with open(filepath, "w") as f:
                json.dump(workflow_data, f, indent=2)

            print(f"‚úì Exported: {filename}")

        print(f"\nExported {len(workflows)} workflows to {output_dir}")
```

#### Git Integration (Automated Backup)

**Bash Script:** `n8n-backup.sh`

```bash
#!/bin/bash
# Automated n8n workflow backup to Git

set -e

BACKUP_DIR="n8n-workflows"
N8N_API_KEY="${N8N_API_KEY}"
N8N_URL="https://n8n-production.up.railway.app/api/v1"

echo "Starting n8n workflow backup..."

# Create backup directory
mkdir -p "$BACKUP_DIR"

# Export workflows using Python script
python3 - <<EOF
import httpx
import json
import os
from pathlib import Path

async def export():
    api_key = os.environ["N8N_API_KEY"]
    headers = {"X-N8N-API-KEY": api_key}

    async with httpx.AsyncClient() as client:
        response = await client.get("${N8N_URL}/workflows", headers=headers)
        workflows = response.json()["data"]

        for workflow in workflows:
            response = await client.get(
                f"${N8N_URL}/workflows/{workflow['id']}",
                headers=headers
            )
            data = response.json()

            filename = f"{workflow['name'].replace(' ', '-').lower()}.json"
            with open(f"${BACKUP_DIR}/{filename}", "w") as f:
                json.dump(data, f, indent=2)

            print(f"Exported: {filename}")

import asyncio
asyncio.run(export())
EOF

# Commit to Git
cd "$BACKUP_DIR"
git add .
git commit -m "chore(n8n): backup workflows $(date +%Y-%m-%d)"
git push origin main

echo "‚úì Backup complete"
```

**Cron Job:** Run daily at 2 AM

```bash
# Add to crontab
crontab -e

# Add line:
0 2 * * * /path/to/n8n-backup.sh >> /var/log/n8n-backup.log 2>&1
```

### Import Workflows

```python
async def import_workflow(
    workflow_json_path: str,
    api_key: str,
    base_url: str
):
    """
    Import workflow from JSON file.

    Args:
        workflow_json_path: Path to workflow JSON file
        api_key: n8n API key
        base_url: n8n API base URL

    Returns:
        Created workflow dict
    """
    import json

    # Read workflow JSON
    with open(workflow_json_path, "r") as f:
        workflow_data = json.load(f)

    # Remove ID (n8n will assign new one)
    if "id" in workflow_data:
        del workflow_data["id"]

    headers = {"X-N8N-API-KEY": api_key}

    async with httpx.AsyncClient() as client:
        response = await client.post(
            f"{base_url}/workflows",
            headers=headers,
            json=workflow_data
        )

        response.raise_for_status()
        created = response.json()

        print(f"‚úì Imported workflow: {created['name']} (ID: {created['id']})")
        return created
```

---

## Python Implementation

### Basic n8n Client

```python
"""
n8n API Client - Basic Implementation

Usage:
    from n8n_client import N8nClient

    client = N8nClient(
        api_key="n8n_api_...",
        base_url="https://n8n-production.up.railway.app/api/v1"
    )

    # Execute workflow
    result = await client.execute_workflow(
        workflow_id="1",
        input_data={"key": "value"}
    )

    # Wait for completion
    status = await client.wait_for_execution(result["data"]["executionId"])
"""

import httpx
import asyncio
import time
import logging
from typing import Optional, Dict, Any, List

logger = logging.getLogger(__name__)


class N8nClient:
    """Basic n8n REST API client."""

    def __init__(self, api_key: str, base_url: str):
        """
        Initialize n8n client.

        Args:
            api_key: n8n API key
            base_url: n8n API base URL (e.g., https://n8n.example.com/api/v1)
        """
        self.api_key = api_key
        self.base_url = base_url.rstrip("/")
        self.headers = {"X-N8N-API-KEY": api_key}

    async def _request(
        self,
        method: str,
        endpoint: str,
        json: dict = None,
        params: dict = None
    ) -> Any:
        """
        Make authenticated n8n API request.

        Args:
            method: HTTP method (GET, POST, etc.)
            endpoint: API endpoint (e.g., "/workflows")
            json: Optional JSON payload
            params: Optional query parameters

        Returns:
            Response JSON data

        Raises:
            httpx.HTTPError: On API errors
        """
        url = f"{self.base_url}{endpoint}"

        async with httpx.AsyncClient(timeout=60.0) as client:
            response = await client.request(
                method,
                url,
                headers=self.headers,
                json=json,
                params=params
            )

            response.raise_for_status()
            return response.json()

    async def list_workflows(self) -> List[Dict[str, Any]]:
        """List all workflows."""
        data = await self._request("GET", "/workflows")
        return data.get("data", [])

    async def get_workflow(self, workflow_id: str) -> Dict[str, Any]:
        """Get workflow details."""
        return await self._request("GET", f"/workflows/{workflow_id}")

    async def execute_workflow(
        self,
        workflow_id: str,
        input_data: Dict[str, Any] = None
    ) -> Dict[str, Any]:
        """
        Execute workflow manually.

        Args:
            workflow_id: n8n workflow ID
            input_data: Optional input data for workflow

        Returns:
            Execution result dict
        """
        result = await self._request(
            "POST",
            f"/workflows/{workflow_id}/execute",
            json=input_data or {}
        )

        logger.info(f"Executed workflow {workflow_id}, execution ID: {result['data']['executionId']}")
        return result

    async def get_execution(self, execution_id: str) -> Dict[str, Any]:
        """Get execution details."""
        return await self._request("GET", f"/executions/{execution_id}")

    async def wait_for_execution(
        self,
        execution_id: str,
        timeout: int = 300,
        poll_interval: int = 2
    ) -> Dict[str, Any]:
        """
        Wait for execution to complete.

        Args:
            execution_id: n8n execution ID
            timeout: Maximum wait time in seconds
            poll_interval: Seconds between status checks

        Returns:
            Final execution data

        Raises:
            TimeoutError: If execution exceeds timeout
        """
        start_time = time.time()

        while True:
            if time.time() - start_time > timeout:
                raise TimeoutError(f"Execution {execution_id} timed out after {timeout}s")

            data = await self.get_execution(execution_id)

            if data.get("finished"):
                logger.info(f"Execution {execution_id} finished")
                return data

            await asyncio.sleep(poll_interval)
```

---

## Production Setup

### Security Hardening

#### 1. Credentials Encryption

n8n encrypts credentials using `N8N_ENCRYPTION_KEY`. **Never change this key** after initial setup or all credentials will be lost.

**Generate Secure Key:**

```bash
# Generate 32-character random string
openssl rand -base64 24 | tr -d '\n' | cut -c1-32
```

**Store in Railway:**

```bash
railway variables set N8N_ENCRYPTION_KEY="<your-32-char-key>"
```

#### 2. Basic Authentication

Enable basic auth for n8n UI:

```bash
railway variables set N8N_BASIC_AUTH_ACTIVE=true
railway variables set N8N_BASIC_AUTH_USER="admin"
railway variables set N8N_BASIC_AUTH_PASSWORD="<secure-password>"
```

#### 3. API Key Rotation

Rotate n8n API keys every 90 days:

1. Create new API key in n8n UI
2. Update GCP Secret Manager:
   ```bash
   gcloud secrets versions add N8N-API --data-file=- <<< "new_api_key"
   ```
3. Restart Claude agent to pick up new key
4. Delete old API key in n8n UI

#### 4. Webhook Security

For production webhooks, use webhook authentication:

```json
{
  "name": "Secure Webhook",
  "type": "n8n-nodes-base.webhook",
  "parameters": {
    "path": "deploy",
    "httpMethod": "POST",
    "authentication": "headerAuth",
    "headerAuth": {
      "name": "X-Webhook-Secret",
      "value": "={{$credentials.webhookSecret.secret}}"
    }
  }
}
```

### Monitoring

#### Workflow Execution Monitoring

```python
async def monitor_workflow_executions(
    client: N8nClient,
    workflow_id: str,
    since: str = None
):
    """
    Monitor workflow executions for failures.

    Args:
        client: N8nClient instance
        workflow_id: Workflow ID to monitor
        since: ISO timestamp to start monitoring from

    Returns:
        List of failed executions
    """
    params = {"workflowId": workflow_id}
    if since:
        params["since"] = since

    executions = await client._request("GET", "/executions", params=params)

    failed = [
        e for e in executions.get("data", [])
        if not e.get("finished") or e.get("status") == "error"
    ]

    if failed:
        logger.warning(f"Found {len(failed)} failed executions for workflow {workflow_id}")

    return failed
```

#### Health Check Endpoint

Add to Railway FastAPI app:

```python
@app.get("/health/n8n")
async def n8n_health_check():
    """Check n8n connectivity."""

    try:
        client = N8nClient(
            api_key=manager.get_secret("N8N-API"),
            base_url=os.getenv("N8N_URL")
        )

        # Simple API call to verify connectivity
        workflows = await client.list_workflows()

        return {
            "status": "healthy",
            "n8n_url": os.getenv("N8N_URL"),
            "workflows_count": len(workflows),
            "timestamp": datetime.utcnow().isoformat()
        }

    except Exception as e:
        logger.error(f"n8n health check failed: {e}")
        return {
            "status": "unhealthy",
            "error": str(e),
            "timestamp": datetime.utcnow().isoformat()
        }
```

---

## Complete Python Client

```python
"""
n8n Client - Production-Ready Implementation

Features:
- Workflow CRUD operations
- Workflow execution with monitoring
- Credential management
- Export/import for version control
- Error handling and retries
- Logging

Usage:
    from src.n8n_client import N8nClient
    from src.secrets_manager import SecretManager

    manager = SecretManager()
    client = N8nClient(
        api_key=manager.get_secret("N8N-API"),
        base_url="https://n8n-production.up.railway.app/api/v1"
    )

    # Execute workflow and wait for completion
    result = await client.execute_and_wait(
        workflow_id="deploy-railway",
        input_data={"environment": "production"},
        timeout=600
    )

    # Export workflows for backup
    await client.export_all_workflows("./backups")
"""

import httpx
import asyncio
import time
import json
import logging
from pathlib import Path
from typing import Optional, Dict, Any, List
from dataclasses import dataclass

logger = logging.getLogger(__name__)


@dataclass
class ExecutionResult:
    """Workflow execution result."""
    execution_id: str
    finished: bool
    success: bool
    started_at: str
    stopped_at: Optional[str]
    data: Dict[str, Any]


class N8nError(Exception):
    """Base n8n error."""
    pass


class N8nExecutionError(N8nError):
    """Workflow execution failed."""
    pass


class N8nClient:
    """
    Production-ready n8n REST API client.

    Handles:
    - Workflow management (CRUD)
    - Workflow execution with monitoring
    - Credential management
    - Export/import for version control
    - Error handling and retries
    """

    def __init__(self, api_key: str, base_url: str):
        """
        Initialize n8n client.

        Args:
            api_key: n8n API key from GCP Secret Manager
            base_url: n8n API base URL (e.g., https://n8n.example.com/api/v1)
        """
        self.api_key = api_key
        self.base_url = base_url.rstrip("/")
        self.headers = {
            "X-N8N-API-KEY": api_key,
            "Accept": "application/json"
        }

    async def _request(
        self,
        method: str,
        endpoint: str,
        json: dict = None,
        params: dict = None,
        max_retries: int = 3
    ) -> Any:
        """
        Make authenticated n8n API request with retry logic.

        Args:
            method: HTTP method
            endpoint: API endpoint
            json: Optional JSON payload
            params: Optional query parameters
            max_retries: Maximum number of retries

        Returns:
            Response JSON data

        Raises:
            N8nError: On API errors
        """
        url = f"{self.base_url}{endpoint}"

        for attempt in range(max_retries):
            try:
                async with httpx.AsyncClient(timeout=60.0) as client:
                    response = await client.request(
                        method,
                        url,
                        headers=self.headers,
                        json=json,
                        params=params
                    )

                    response.raise_for_status()
                    return response.json()

            except httpx.HTTPStatusError as e:
                if e.response.status_code == 429:  # Rate limited
                    wait_time = 2 ** attempt
                    logger.warning(f"Rate limited, waiting {wait_time}s...")
                    await asyncio.sleep(wait_time)
                    continue

                if attempt == max_retries - 1:
                    raise N8nError(f"HTTP error: {e}")

            except httpx.TimeoutException:
                if attempt == max_retries - 1:
                    raise N8nError("Request timed out")
                await asyncio.sleep(2 ** attempt)

        raise N8nError(f"Failed after {max_retries} attempts")

    # ============ Workflow Operations ============

    async def list_workflows(self) -> List[Dict[str, Any]]:
        """
        List all workflows.

        Returns:
            List of workflow summary dicts
        """
        data = await self._request("GET", "/workflows")
        workflows = data.get("data", [])

        logger.info(f"Listed {len(workflows)} workflows")
        return workflows

    async def get_workflow(self, workflow_id: str) -> Dict[str, Any]:
        """
        Get workflow details including nodes and connections.

        Args:
            workflow_id: n8n workflow ID

        Returns:
            Full workflow dict
        """
        workflow = await self._request("GET", f"/workflows/{workflow_id}")
        logger.debug(f"Retrieved workflow: {workflow.get('name')}")
        return workflow

    async def create_workflow(self, workflow_data: Dict[str, Any]) -> Dict[str, Any]:
        """
        Create new workflow from JSON definition.

        Args:
            workflow_data: Workflow JSON (nodes, connections, settings)

        Returns:
            Created workflow dict
        """
        # Remove ID if present (n8n will assign new one)
        if "id" in workflow_data:
            del workflow_data["id"]

        workflow = await self._request("POST", "/workflows", json=workflow_data)
        logger.info(f"Created workflow: {workflow['name']} (ID: {workflow['id']})")

        return workflow

    async def update_workflow(
        self,
        workflow_id: str,
        workflow_data: Dict[str, Any]
    ) -> Dict[str, Any]:
        """
        Update existing workflow.

        Args:
            workflow_id: n8n workflow ID
            workflow_data: Updated workflow JSON

        Returns:
            Updated workflow dict
        """
        workflow = await self._request(
            "PUT",
            f"/workflows/{workflow_id}",
            json=workflow_data
        )

        logger.info(f"Updated workflow: {workflow['name']}")
        return workflow

    async def delete_workflow(self, workflow_id: str):
        """Delete workflow."""
        await self._request("DELETE", f"/workflows/{workflow_id}")
        logger.info(f"Deleted workflow: {workflow_id}")

    async def activate_workflow(self, workflow_id: str):
        """Activate workflow (enable triggers)."""
        await self._request("POST", f"/workflows/{workflow_id}/activate")
        logger.info(f"Activated workflow: {workflow_id}")

    async def deactivate_workflow(self, workflow_id: str):
        """Deactivate workflow (disable triggers)."""
        await self._request("POST", f"/workflows/{workflow_id}/deactivate")
        logger.info(f"Deactivated workflow: {workflow_id}")

    # ============ Execution Operations ============

    async def execute_workflow(
        self,
        workflow_id: str,
        input_data: Dict[str, Any] = None
    ) -> str:
        """
        Execute workflow manually.

        Args:
            workflow_id: n8n workflow ID
            input_data: Optional input data for workflow

        Returns:
            Execution ID
        """
        result = await self._request(
            "POST",
            f"/workflows/{workflow_id}/execute",
            json=input_data or {}
        )

        execution_id = result["data"]["executionId"]
        logger.info(f"Started execution: {execution_id}")

        return execution_id

    async def get_execution(self, execution_id: str) -> ExecutionResult:
        """
        Get execution details.

        Args:
            execution_id: n8n execution ID

        Returns:
            ExecutionResult object
        """
        data = await self._request("GET", f"/executions/{execution_id}")

        return ExecutionResult(
            execution_id=data["id"],
            finished=data.get("finished", False),
            success=data.get("status") != "error",
            started_at=data.get("startedAt", ""),
            stopped_at=data.get("stoppedAt"),
            data=data
        )

    async def wait_for_execution(
        self,
        execution_id: str,
        timeout: int = 300,
        poll_interval: int = 2
    ) -> ExecutionResult:
        """
        Wait for execution to complete.

        Args:
            execution_id: n8n execution ID
            timeout: Maximum wait time in seconds
            poll_interval: Seconds between status checks

        Returns:
            Final ExecutionResult

        Raises:
            TimeoutError: If execution exceeds timeout
            N8nExecutionError: If execution fails
        """
        start_time = time.time()

        while True:
            if time.time() - start_time > timeout:
                raise TimeoutError(
                    f"Execution {execution_id} timed out after {timeout}s"
                )

            result = await self.get_execution(execution_id)

            if result.finished:
                if not result.success:
                    raise N8nExecutionError(
                        f"Execution {execution_id} failed: {result.data.get('status')}"
                    )

                logger.info(f"Execution {execution_id} completed successfully")
                return result

            logger.debug(f"Execution {execution_id} still running...")
            await asyncio.sleep(poll_interval)

    async def execute_and_wait(
        self,
        workflow_id: str,
        input_data: Dict[str, Any] = None,
        timeout: int = 300
    ) -> ExecutionResult:
        """
        Execute workflow and wait for completion.

        Args:
            workflow_id: n8n workflow ID
            input_data: Optional input data
            timeout: Maximum wait time in seconds

        Returns:
            Final ExecutionResult

        Raises:
            TimeoutError: If execution exceeds timeout
            N8nExecutionError: If execution fails
        """
        execution_id = await self.execute_workflow(workflow_id, input_data)
        return await self.wait_for_execution(execution_id, timeout)

    # ============ Export/Import Operations ============

    async def export_workflow(
        self,
        workflow_id: str,
        output_path: str
    ):
        """
        Export workflow to JSON file.

        Args:
            workflow_id: n8n workflow ID
            output_path: File path to save JSON
        """
        workflow = await self.get_workflow(workflow_id)

        with open(output_path, "w") as f:
            json.dump(workflow, f, indent=2)

        logger.info(f"Exported workflow to {output_path}")

    async def export_all_workflows(self, output_dir: str):
        """
        Export all workflows to JSON files.

        Args:
            output_dir: Directory to save workflow JSON files
        """
        workflows = await self.list_workflows()

        output_path = Path(output_dir)
        output_path.mkdir(exist_ok=True, parents=True)

        for workflow in workflows:
            # Sanitize filename
            filename = f"{workflow['name'].replace(' ', '-').lower()}.json"
            filepath = output_path / filename

            await self.export_workflow(workflow["id"], str(filepath))

        logger.info(f"Exported {len(workflows)} workflows to {output_dir}")

    async def import_workflow(
        self,
        workflow_json_path: str,
        activate: bool = False
    ) -> Dict[str, Any]:
        """
        Import workflow from JSON file.

        Args:
            workflow_json_path: Path to workflow JSON file
            activate: If True, activate workflow after import

        Returns:
            Created workflow dict
        """
        with open(workflow_json_path, "r") as f:
            workflow_data = json.load(f)

        workflow = await self.create_workflow(workflow_data)

        if activate:
            await self.activate_workflow(workflow["id"])

        logger.info(f"Imported workflow: {workflow['name']}")
        return workflow
```

---

## Sources

- [n8n API Documentation](https://docs.n8n.io/api/)
- [n8n Workflow Export and Import](https://docs.n8n.io/workflows/export-import/)
- [Create and Run Workflows](https://docs.n8n.io/workflows/create/)
- [n8n Code Node Documentation](https://docs.n8n.io/integrations/builtin/core-nodes/n8n-nodes-base.code/)
- [Railway n8n Template](https://railway.com/deploy/n8n)
- [Railway n8n GitHub Template](https://github.com/railwayapp-templates/n8n)
- [n8n Claude Integration](https://n8n.io/integrations/claude/)
- [n8n Webhook and Claude Automation](https://n8n.io/integrations/webhook/and/claude/)
- [n8n API Authentication](https://docs.n8n.io/api/authentication/)
- [A Detailed Guide to Using n8n API with Python (2025-12-10)](https://martinuke0.github.io/posts/2025-12-10-a-detailed-guide-to-using-the-n8n-api-with-python/)
- [n8n Workflows as Code](https://mfyz.com/i-found-a-way-to-make-n8n-workflows-as-code/)

---

## Next Steps

1. ‚úÖ Deploy n8n to Railway using template
2. ‚úÖ Create owner account and generate API key
3. ‚úÖ Store API key in GCP Secret Manager
4. ‚úÖ Implement `src/n8n_client.py` module
5. ‚úÖ Create sample workflows for Railway deployment
6. ‚úÖ Set up automated backup to Git
7. ‚úÖ Configure webhooks for Claude integration
8. ‚úÖ Test bidirectional Claude ‚Üî n8n communication

**Last Updated:** 2026-01-12
