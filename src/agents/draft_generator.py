"""Draft Reply Generator - Creates intelligent email reply drafts.

Generates contextual reply drafts based on:
- Email content and tone
- Sender relationship (known contact, organization, etc.)
- Calendar context (availability)
- User preferences

SAFETY: NEVER sends emails automatically - only generates drafts for approval.

ADR-014 Phase 2: Draft Reply Generator
"""

import json
import logging
import re
from dataclasses import dataclass
from enum import Enum
from typing import Any

import httpx

logger = logging.getLogger(__name__)


class ToneType(Enum):
    """Email tone types."""

    FORMAL = "formal"  # Official, business
    PROFESSIONAL = "professional"  # Work colleagues
    FRIENDLY = "friendly"  # Known contacts
    CASUAL = "casual"  # Friends, family


class ReplyType(Enum):
    """Types of reply actions."""

    ACKNOWLEDGE = "acknowledge"  # Simple confirmation
    ACCEPT = "accept"  # Accept invitation/request
    DECLINE = "decline"  # Politely decline
    REQUEST_INFO = "request_info"  # Ask for more details
    PROVIDE_INFO = "provide_info"  # Answer a question
    SCHEDULE = "schedule"  # Propose meeting time
    FOLLOWUP = "followup"  # Follow up on previous email


@dataclass
class DraftReply:
    """Generated email reply draft."""

    email_id: str
    reply_type: ReplyType
    tone: ToneType
    subject: str
    body_hebrew: str
    body_english: str | None
    suggested_attachments: list[str]
    calendar_conflicts: list[str]
    confidence: float  # 0-1, how confident the AI is in this draft
    alternatives: list[str]  # Alternative phrasings


# Hebrew reply templates by type
HEBREW_TEMPLATES = {
    ReplyType.ACKNOWLEDGE: [
        "×ª×•×“×” ×¢×œ ×”×¤× ×™×™×”. ×§×™×‘×œ×ª×™ ××ª ×”×•×“×¢×ª×š ×•××˜×¤×œ ×‘×” ×‘×”×§×“×.",
        "×××©×¨ ×§×‘×œ×ª ×”××™×™×œ. ××—×–×•×¨ ××œ×™×š ×‘×”××©×š.",
        "×©×œ×•×, ×§×™×‘×œ×ª×™ ××ª ×”××™×™×œ ×•××¢×“×›×Ÿ ×‘×”×§×“× ×”××¤×©×¨×™.",
    ],
    ReplyType.ACCEPT: [
        "×ª×•×“×” ×¢×œ ×”×”×–×× ×”, ××©××— ×œ×”×©×ª×ª×£.",
        "×××©×¨ ××ª ×”×¤×’×™×©×”. × ×ª×¨××”!",
        "×‘×©××—×”, ××ª××™× ×œ×™.",
    ],
    ReplyType.DECLINE: [
        "×ª×•×“×” ×¢×œ ×”×¤× ×™×™×”. ×œ×¦×¢×¨×™, ×œ× ××•×›×œ ×œ×”×©×ª×ª×£ ×‘×ª××¨×™×š ×–×”.",
        "××¦×˜×¢×¨, ×™×© ×œ×™ ×”×ª×—×™×™×‘×•×ª ××—×¨×ª ×‘××•×ª×• ×–××Ÿ. ×”×× ×™×© ×ª××¨×™×š ×—×œ×•×¤×™?",
        "××•×“×” ×¢×œ ×”×”×–×× ×”, ××š ×œ× ××•×›×œ ×œ×”×’×™×¢ ×”×¤×¢×.",
    ],
    ReplyType.REQUEST_INFO: [
        "×ª×•×“×” ×¢×œ ×”×¤× ×™×™×”. ××©××— ×œ×§×‘×œ ×¤×¨×˜×™× × ×•×¡×¤×™× ×œ×’×‘×™:",
        "×œ×¤× ×™ ×©××•×›×œ ×œ×”×©×™×‘, ××¦×˜×¨×š ××™×“×¢ × ×•×¡×£:",
        "×”×× ×ª×•×›×œ ×œ×¤×¨×˜ ×™×•×ª×¨ ×‘× ×•×’×¢ ×œ:",
    ],
    ReplyType.SCHEDULE: [
        "××©××— ×œ×ª×× ×¤×’×™×©×”. ×”×–×× ×™× ×”×¤× ×•×™×™× ×©×œ×™ ×”×:",
        "××•×–××Ÿ ×œ×‘×—×•×¨ ×××—×“ ×”×–×× ×™× ×”×‘××™×:",
        "×‘×•× × ×§×‘×¢ ×©×™×—×”. ××ª××™× ×œ×™ ×‘:",
    ],
}


class DraftGenerator:
    """Generates intelligent email reply drafts.

    Uses LLM to understand email context and generate appropriate responses.
    NEVER sends emails - only creates drafts for user approval.

    Example:
        generator = DraftGenerator()
        draft = await generator.generate_reply(
            email_subject="×‘×§×©×” ×œ×¤×’×™×©×”",
            email_body="×©×œ×•×, ×”×× × ×•×›×œ ×œ×”×™×¤×’×© ×”×©×‘×•×¢?",
            sender="colleague@company.com",
            reply_type=ReplyType.SCHEDULE,
            calendar_context=["×™×•× ×’ 10:00 - ×¤× ×•×™", "×™×•× ×“ 14:00 - ×¤× ×•×™"]
        )
    """

    def __init__(
        self,
        litellm_url: str = "https://litellm-gateway-production-0339.up.railway.app",
    ):
        """Initialize DraftGenerator.

        Args:
            litellm_url: URL of LiteLLM Gateway
        """
        self.litellm_url = litellm_url

    def _detect_tone(self, sender: str, subject: str, body: str) -> ToneType:
        """Detect the appropriate tone for reply.

        Args:
            sender: Email sender
            subject: Email subject
            body: Email body

        Returns:
            Appropriate tone type
        """
        combined = f"{sender} {subject} {body}".lower()

        # Formal indicators
        formal_patterns = [
            r"gov\.il",
            r"@bank",
            r"××©×¨×“",
            r"×œ×›×‘×•×“",
            r"×‘×‘×¨×›×”",
            r"dear sir",
            r"official",
        ]
        for pattern in formal_patterns:
            if re.search(pattern, combined, re.IGNORECASE):
                return ToneType.FORMAL

        # Professional indicators
        professional_patterns = [
            r"@company",
            r"@corp",
            r"meeting",
            r"×¤×’×™×©×”",
            r"project",
            r"×¤×¨×•×™×§×˜",
        ]
        for pattern in professional_patterns:
            if re.search(pattern, combined, re.IGNORECASE):
                return ToneType.PROFESSIONAL

        # Casual indicators
        casual_patterns = [
            r"×”×™×™",
            r"hey",
            r"××” ×§×•×¨×”",
            r"what's up",
            r"@gmail\.com",
            r"@hotmail",
        ]
        for pattern in casual_patterns:
            if re.search(pattern, combined, re.IGNORECASE):
                return ToneType.FRIENDLY

        return ToneType.PROFESSIONAL  # Default

    def _detect_reply_type(self, subject: str, body: str) -> ReplyType:
        """Detect what type of reply is needed.

        Args:
            subject: Email subject
            body: Email body

        Returns:
            Appropriate reply type
        """
        combined = f"{subject} {body}".lower()

        # Meeting/schedule indicators
        if any(
            word in combined
            for word in ["×¤×’×™×©×”", "meeting", "×œ×ª××", "schedule", "×–××Ÿ", "time", "×™×•××Ÿ"]
        ):
            return ReplyType.SCHEDULE

        # Information request indicators
        if any(
            word in combined
            for word in ["?", "×”××", "××”", "××™×š", "×œ××”", "what", "how", "why", "can you"]
        ):
            return ReplyType.REQUEST_INFO

        # Invitation indicators
        if any(
            word in combined
            for word in ["×”×–×× ×”", "invitation", "invite", "××•×–××Ÿ", "invited"]
        ):
            return ReplyType.ACCEPT  # Default to accept, user can change

        # Follow-up indicators
        if any(
            word in combined
            for word in ["×”××©×š", "follow", "×¢×“×›×•×Ÿ", "update", "×ª×–×›×•×¨×ª", "reminder"]
        ):
            return ReplyType.FOLLOWUP

        return ReplyType.ACKNOWLEDGE  # Default

    async def _generate_with_llm(
        self,
        email_subject: str,
        email_body: str,
        sender: str,
        reply_type: ReplyType,
        tone: ToneType,
        calendar_context: list[str] | None = None,
        user_notes: str | None = None,
    ) -> dict:
        """Generate reply using LLM.

        Args:
            email_subject: Original email subject
            email_body: Original email body
            sender: Email sender
            reply_type: Type of reply needed
            tone: Tone to use
            calendar_context: List of free/busy times
            user_notes: Additional notes from user

        Returns:
            Generated reply data
        """
        from openai import AsyncOpenAI

        tone_instructions = {
            ToneType.FORMAL: "×¨×©××™ ×•××›×•×‘×“, ×¢× ×¤× ×™×™×” ×× ×•××¡×ª",
            ToneType.PROFESSIONAL: "××§×¦×•×¢×™ ×•×‘×¨×•×¨, ×™×“×™×“×•×ª×™ ××š ×¢× ×™× ×™",
            ToneType.FRIENDLY: "×™×“×™×“×•×ª×™ ×•×—×, ××š ××›×•×‘×“",
            ToneType.CASUAL: "×§×œ×™×œ ×•×œ× ×¨×©××™, ×›××• ×œ×—×‘×¨",
        }

        reply_instructions = {
            ReplyType.ACKNOWLEDGE: "××©×¨ ×§×‘×œ×ª ×”××™×™×œ ×•×”×‘×˜×— ××¢× ×” ×‘×”××©×š",
            ReplyType.ACCEPT: "×§×‘×œ ××ª ×”×”×–×× ×”/×‘×§×©×” ×‘×¦×•×¨×” ×—×™×•×‘×™×ª",
            ReplyType.DECLINE: "×¡×¨×‘ ×‘× ×™××•×¡, ×”×¦×¢ ×—×œ×•×¤×” ×× ××¤×©×¨",
            ReplyType.REQUEST_INFO: "×‘×§×© ××™×“×¢ × ×•×¡×£ ×œ×¤× ×™ ××ª×Ÿ ×ª×©×•×‘×”",
            ReplyType.PROVIDE_INFO: "×¡×¤×§ ××ª ×”××™×“×¢ ×”××‘×•×§×© ×‘×¦×•×¨×” ×‘×¨×•×¨×”",
            ReplyType.SCHEDULE: "×”×¦×¢ ×–×× ×™× ×œ×¤×’×™×©×” ××ª×•×š ×”×–×× ×™× ×”×¤× ×•×™×™×",
            ReplyType.FOLLOWUP: "×¢×§×•×‘ ××—×¨×™ ×”× ×•×©×, ×‘×§×© ×¢×“×›×•×Ÿ",
        }

        prompt = f"""××ª×” ×¢×•×–×¨ ×©×›×•×ª×‘ ×˜×™×•×˜×•×ª ××™×™×œ×™× ×‘×¢×‘×¨×™×ª.

## ×”××™×™×œ ×”××§×•×¨×™
× ×•×©×: {email_subject}
×××ª: {sender}
×ª×•×›×Ÿ:
{email_body}

## ×¡×•×’ ×”×ª×©×•×‘×” ×”× ×“×¨×©
{reply_instructions.get(reply_type, "×ª×©×•×‘×” ×›×œ×œ×™×ª")}

## ×˜×•×Ÿ × ×“×¨×©
{tone_instructions.get(tone, "××§×¦×•×¢×™")}

{f"## ×”×§×©×¨ ×™×•××Ÿ (×–×× ×™× ×¤× ×•×™×™×){chr(10)}" + chr(10).join(calendar_context) if calendar_context else ""}

{f"## ×”×¢×¨×•×ª × ×•×¡×¤×•×ª{chr(10)}{user_notes}" if user_notes else ""}

## ×”××©×™××” ×©×œ×š
×›×ª×•×‘ ×˜×™×•×˜×ª ×ª×©×•×‘×” ×œ××™×™×œ. ×”×ª×©×•×‘×” ×¦×¨×™×›×” ×œ×”×™×•×ª:
1. ×‘×¢×‘×¨×™×ª (××œ× ×× ×”××™×™×œ ×”××§×•×¨×™ ×‘×× ×’×œ×™×ª)
2. ×‘×˜×•×Ÿ ×”××ª××™×
3. ×§×¦×¨×” ×•×××•×§×“×ª
4. ×× ×•××¡×ª ×•××§×¦×•×¢×™×ª

## ×¤×•×¨××˜ ×”×ª×©×•×‘×” (JSON)
{{
  "subject": "RE: × ×•×©× ××ª××™×",
  "body": "×ª×•×›×Ÿ ×”×ª×©×•×‘×” ×‘×¢×‘×¨×™×ª",
  "body_english": "English version if original was in English, null otherwise",
  "key_points": ["× ×§×•×“×” 1", "× ×§×•×“×” 2"],
  "suggested_attachments": ["××¡××š ×©×›×“××™ ×œ×¦×¨×£"],
  "alternative_phrases": ["× ×™×¡×•×— ×—×œ×•×¤×™ 1", "× ×™×¡×•×— ×—×œ×•×¤×™ 2"],
  "confidence": 0.85,
  "warnings": ["××–×”×¨×” ×× ×™×© ××©×”×• ×©×¦×¨×™×š ×œ×©×™× ×œ×‘ ××œ×™×•"]
}}

×¢× ×” ×¨×§ ×‘-JSON."""

        try:
            client = AsyncOpenAI(base_url=self.litellm_url, api_key="dummy")

            response = await client.chat.completions.create(
                model="claude-sonnet",
                messages=[{"role": "user", "content": prompt}],
                temperature=0.4,
                max_tokens=1500,
            )

            content = response.choices[0].message.content

            # Clean markdown
            if content.startswith("```"):
                content = content.split("\n", 1)[1]
            if content.endswith("```"):
                content = content.rsplit("\n", 1)[0]

            return json.loads(content.strip())

        except Exception as e:
            logger.error(f"LLM draft generation failed: {e}")

            # Fallback to template
            templates = HEBREW_TEMPLATES.get(reply_type, HEBREW_TEMPLATES[ReplyType.ACKNOWLEDGE])
            return {
                "subject": f"RE: {email_subject}",
                "body": templates[0],
                "body_english": None,
                "key_points": [],
                "suggested_attachments": [],
                "alternative_phrases": templates[1:],
                "confidence": 0.3,
                "warnings": ["× ×•×¦×¨ ××ª×‘× ×™×ª ×¢×§×‘ ×©×’×™××”"],
            }

    async def generate_reply(
        self,
        email_id: str,
        email_subject: str,
        email_body: str,
        sender: str,
        reply_type: ReplyType | None = None,
        tone: ToneType | None = None,
        calendar_context: list[str] | None = None,
        user_notes: str | None = None,
    ) -> DraftReply:
        """Generate a reply draft for an email.

        Args:
            email_id: ID of the email being replied to
            email_subject: Original email subject
            email_body: Original email body/snippet
            sender: Email sender
            reply_type: Type of reply (auto-detected if None)
            tone: Tone to use (auto-detected if None)
            calendar_context: Free/busy times for scheduling
            user_notes: Additional context from user

        Returns:
            DraftReply with the generated draft
        """
        # Auto-detect if not specified
        if tone is None:
            tone = self._detect_tone(sender, email_subject, email_body)

        if reply_type is None:
            reply_type = self._detect_reply_type(email_subject, email_body)

        logger.info(f"Generating {reply_type.value} reply with {tone.value} tone")

        # Generate with LLM
        result = await self._generate_with_llm(
            email_subject=email_subject,
            email_body=email_body,
            sender=sender,
            reply_type=reply_type,
            tone=tone,
            calendar_context=calendar_context,
            user_notes=user_notes,
        )

        return DraftReply(
            email_id=email_id,
            reply_type=reply_type,
            tone=tone,
            subject=result.get("subject", f"RE: {email_subject}"),
            body_hebrew=result.get("body", ""),
            body_english=result.get("body_english"),
            suggested_attachments=result.get("suggested_attachments", []),
            calendar_conflicts=result.get("warnings", []),
            confidence=result.get("confidence", 0.5),
            alternatives=result.get("alternative_phrases", []),
        )

    async def generate_batch(
        self,
        emails: list[dict],
        calendar_context: list[str] | None = None,
    ) -> list[DraftReply]:
        """Generate drafts for multiple emails.

        Args:
            emails: List of email dicts
            calendar_context: Shared calendar context

        Returns:
            List of DraftReply objects
        """
        drafts = []

        for email in emails:
            draft = await self.generate_reply(
                email_id=email.get("id", ""),
                email_subject=email.get("subject", ""),
                email_body=email.get("snippet", ""),
                sender=email.get("from", ""),
                calendar_context=calendar_context,
            )
            drafts.append(draft)

        return drafts

    def format_draft_for_telegram(self, draft: DraftReply) -> str:
        """Format a draft for Telegram display.

        Args:
            draft: The generated draft

        Returns:
            Formatted Telegram message
        """
        confidence_emoji = "ğŸŸ¢" if draft.confidence > 0.7 else "ğŸŸ¡" if draft.confidence > 0.4 else "ğŸ”´"

        lines = [
            f"âœ‰ï¸ *×˜×™×•×˜×ª ×ª×©×•×‘×”*",
            f"",
            f"*× ×•×©×:* {draft.subject}",
            f"*×¡×•×’:* {draft.reply_type.value} | *×˜×•×Ÿ:* {draft.tone.value}",
            f"*×‘×™×˜×—×•×Ÿ:* {confidence_emoji} {int(draft.confidence * 100)}%",
            f"",
            f"â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”",
            f"",
            f"{draft.body_hebrew}",
            f"",
            f"â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”",
        ]

        if draft.suggested_attachments:
            lines.append("")
            lines.append("ğŸ“ *××•××œ×¥ ×œ×¦×¨×£:*")
            for att in draft.suggested_attachments:
                lines.append(f"â€¢ {att}")

        if draft.alternatives:
            lines.append("")
            lines.append("ğŸ”„ *× ×™×¡×•×—×™× ×—×œ×•×¤×™×™×:*")
            for i, alt in enumerate(draft.alternatives[:2], 1):
                lines.append(f"{i}. {alt[:100]}...")

        lines.append("")
        lines.append("_âš ï¸ ×–×• ×˜×™×•×˜×” ×‘×œ×‘×“ - ×œ× × ×©×œ×—×”!_")

        return "\n".join(lines)


async def main() -> None:
    """Test DraftGenerator."""
    logging.basicConfig(level=logging.INFO)

    generator = DraftGenerator()

    # Test with a meeting request
    draft = await generator.generate_reply(
        email_id="test123",
        email_subject="×‘×§×©×” ×œ×¤×’×™×©×”",
        email_body="×©×œ×•×, ×”×× × ×•×›×œ ×œ×ª×× ×¤×’×™×©×” ×”×©×‘×•×¢ ×œ×“×•×Ÿ ×‘×¤×¨×•×™×§×˜ ×”×—×“×©?",
        sender="colleague@company.com",
        calendar_context=[
            "×™×•× ×’ 10:00-11:00 - ×¤× ×•×™",
            "×™×•× ×“ 14:00-15:00 - ×¤× ×•×™",
            "×™×•× ×” 09:00-10:00 - ×¤× ×•×™",
        ],
    )

    print("\n=== Generated Draft ===")
    print(f"Subject: {draft.subject}")
    print(f"Type: {draft.reply_type.value}")
    print(f"Tone: {draft.tone.value}")
    print(f"Confidence: {draft.confidence}")
    print(f"\nBody:\n{draft.body_hebrew}")

    print("\n=== Telegram Format ===")
    print(generator.format_draft_for_telegram(draft))


if __name__ == "__main__":
    import asyncio

    asyncio.run(main())
